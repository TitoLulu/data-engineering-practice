# data-engineering-practice

# Motivation
As someone who works in the matrix of Data Science and Data Engineering, I aspire to build on my DE skillset inorder to enhance my understanding of the field and tools, imbibe industry best practice, and improve my efficiency. 

By now I have a good grounding on building data pipelines and owning ETL processes from start to finish. Obviously, I could learn more, in particular creating efficient data warehouses, and developing efficiency in tools such as Airflow, Spark, and AWS tools. 

My learnings are inspired by Robert Chang's medium tutorials on Data Engineering best practices at Airbnb, and Udacity's Data Engineering Nano Degree Program.

# Important skills to learn
```
Algorithms and Data Structures (Refresher)
SQL Advanced (Refresher)
Python / Scala Programming (Continue Mastering)
Big Data Tools (Continue Mastering) (Apache Kafka, Apache Spark)
Cloud Platforms (Amazon EC2,AWS Lambda,Amazon S3,DynamoDB)
Distributed Systems 
Data Pipelines
```
# Text Books

[Introduction to Algorithms](https://amzn.to/2CvJvpq)

[AWS Data Pipeline Developer Guide](https://www.amazon.com/AWS-Data-Pipeline-Developer-Guide-ebook/dp/B07644C8TH/ref=sr_1_6?crid=2TJLFTBC1DQEY&dchild=1&keywords=data+engineering&qid=1592077019&sprefix=data+engin%2Caps%2C337&sr=8-6)


